{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-context learning for Citation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codyaldaz/repositories/dspy_scirepeval/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "# from operator import add\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_candidate_data = pd.read_csv('darwin/test.qrel.cid', sep=' ', header=None, names=['query', 'candidate', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(query_papers): 115\n",
      "len(candidate_papers): 637\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('darwin/qpaper_to_emb', 'r') as f:\n",
    "    query_papers = [line.strip() for line in f]\n",
    "\n",
    "with open('darwin/cpaper_to_emb', 'r') as f:\n",
    "    candidate_papers = [line.strip() for line in f]\n",
    "\n",
    "print(f'len(query_papers): {len(query_papers)}')\n",
    "print(f'len(candidate_papers): {len(candidate_papers)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     query candidate  bool\n",
      "0  3498240   1824499     1\n",
      "1  3498240  53645322     0\n",
      "2  3498240   1915951     0\n",
      "3  3498240   3048298     0\n",
      "4  3498240   3627503     0\n",
      "Number of query candidate pairs with valid files: 651\n"
     ]
    }
   ],
   "source": [
    "valid_rows = pd.DataFrame()\n",
    "query_dir = 'darwin/query_papers'\n",
    "candidate_dir = 'darwin/candidate_papers'\n",
    "# Iterate over the rows of the data\n",
    "for _, row in query_candidate_data.iterrows():\n",
    "    query_file = os.path.join(query_dir, str(row['query']) + '.pdf')\n",
    "    candidate_file = os.path.join(candidate_dir, str(row['candidate']) + '.pdf')\n",
    "\n",
    "    # Check if both files exist\n",
    "    if os.path.isfile(query_file) and os.path.isfile(candidate_file):\n",
    "        # If both files exist, append the row to valid_rows\n",
    "        valid_rows = valid_rows._append(row)\n",
    "\n",
    "# Reset the index of valid_rows\n",
    "valid_rows.reset_index(drop=True, inplace=True)\n",
    "print(valid_rows.head())\n",
    "print(f'Number of query candidate pairs with valid files: {len(valid_rows)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"query_file\": query_file, \"candidate_file\": candidate_file, \"cites\": bool(bool_)} for query_file, candidate_file, bool_ in zip(valid_rows['query'], valid_rows['candidate'], valid_rows['bool'])]\n",
    "data = [dspy.Example(**x).with_inputs('query_file', 'candidate_file') for x in data]\n",
    "\n",
    "def split_data(data, split_ratio, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(data))\n",
    "    split_index = int(split_ratio * len(data))\n",
    "    train_indices = indices[:split_index]\n",
    "    test_indices = indices[split_index:]\n",
    "    trainset = [data[i] for i in train_indices]\n",
    "    testset = [data[i] for i in test_indices]\n",
    "    return trainset, testset\n",
    "\n",
    "trainset, testset = split_data(data, 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = dspy.OpenAI(model=\"gpt-3.5-turbo\")\n",
    "dspy.settings.configure(lm=llm, rm=None)\n",
    "\n",
    "client = OpenAI(\n",
    "    # this is also the default, it can be omitted\n",
    "    api_key=os.environ['OPENAI_API_KEY'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunker:\n",
    "    def __init__(self, context_window=3000, max_windows=5):\n",
    "        self.context_window = context_window\n",
    "        self.max_windows = max_windows\n",
    "        self.window_overlap = 0.02\n",
    "\n",
    "    def __call__(self, paper):\n",
    "        snippet_idx = 0\n",
    "\n",
    "        while snippet_idx < self.max_windows and paper:\n",
    "            endpos = int(self.context_window * (1.0 + self.window_overlap))\n",
    "            snippet, paper = paper[:endpos], paper[endpos:]\n",
    "\n",
    "            next_newline_pos = snippet.rfind('\\n')\n",
    "            if paper and next_newline_pos != -1 and next_newline_pos >= self.context_window // 2:\n",
    "                paper = snippet[next_newline_pos+1:] + paper\n",
    "                snippet = snippet[:next_newline_pos]\n",
    "\n",
    "            yield snippet_idx, snippet.strip()\n",
    "            snippet_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSPy Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model=\"text-embedding-3-small\", save_file=None):\n",
    "    if save_file and Path(save_file).exists():\n",
    "        with open(save_file, 'r') as f:\n",
    "            print(f\"Loading embeddings from {save_file}\")\n",
    "            embeddings = [ast.literal_eval(line.strip()) for line in f]\n",
    "        return embeddings\n",
    "        \n",
    "    try:\n",
    "        response = client.embeddings.create(input=texts, model=model)\n",
    "        embeddings = [embedding.embedding for embedding in response.data]\n",
    "        if save_file: # Save the embeddings to a file\n",
    "            with open(save_file, 'w') as f:\n",
    "                print(f\"Saving embeddings to {save_file}\")\n",
    "                for embedding in embeddings:\n",
    "                    f.write(str(embedding) + '\\n')\n",
    "        return embeddings\n",
    "    except Exception as e:\n",
    "        print(\"Error during API call:\", e)\n",
    "        return []\n",
    "    \n",
    "def get_most_similar_chunk(query_embedding, candidate_embeddings, candidate_chunks):\n",
    "    similarities = np.dot(candidate_embeddings, query_embedding) / (norm(candidate_embeddings, axis=1) * norm(query_embedding))\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    return candidate_chunks[most_similar_idx]\n",
    "    \n",
    "    \n",
    "class PredictCitation(dspy.Signature):\n",
    "    __doc__ = \"\"\"Predict if the two chunks are related by a citation.\"\"\"\n",
    "    query_chunk: str = dspy.InputField(desc='Query chunk to compare to the candidate chunk.')\n",
    "    candidate_chunk: str = dspy.InputField(desc='Candidate chunk to compare to the query chunk.')\n",
    "    answer: bool = dspy.OutputField(desc=\"either True or False\", prefix=\"Answer:\")\n",
    "\n",
    "\n",
    "class PredictCitationAndResolve(dspy.Module):\n",
    "    def __init__(self, context_window=3000, max_windows=5, resolve_function=any,\n",
    "                 candidate_folder='darwin/candidate_papers', query_folder='darwin/query_papers'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.chunk = Chunker(context_window=context_window, max_windows=max_windows)\n",
    "        self.predict = dspy.TypedPredictor(PredictCitation)\n",
    "        # self.predict = dspy.ChainOfThought(PredictCitation)\n",
    "        self.resolve_function = resolve_function\n",
    "        self.query_folder = query_folder\n",
    "        self.candidate_folder = candidate_folder\n",
    "        os.mkdir('embeddings', exist_ok=True)\n",
    "        \n",
    "\n",
    "    def forward(self, query_file, candidate_file):\n",
    "        predictions = []\n",
    "        \n",
    "        # Get the text from the pdfs\n",
    "        query_pdf = PdfReader(f'{self.query_folder}/{query_file}.pdf')\n",
    "        query_text = \"\"\n",
    "        for page in query_pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                query_text += page_text + \" \"  # Adding space to separate text between pages\n",
    "        query_text = query_text.replace(\"\\n\", \" \")\n",
    "        \n",
    "        candidate_pdf = PdfReader(f'{self.candidate_folder}/{candidate_file}.pdf')\n",
    "        candidate_text = \"\"\n",
    "        for page in candidate_pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                candidate_text += page_text + \" \"\n",
    "        candidate_text = candidate_text.replace(\"\\n\", \" \")\n",
    "        \n",
    "        # for each chunk in the paper\n",
    "        query_chunks = [snippet for _, snippet in self.chunk(query_text)]\n",
    "        candidate_chunks = [snippet for _, snippet in self.chunk(candidate_text)]\n",
    "        \n",
    "        # Create embeddings for the chunks\n",
    "        candidate_embeddings = get_embeddings(candidate_chunks, save_file=f'embeddings/candidate_{candidate_file}.emb')\n",
    "        query_embeddings = get_embeddings(query_chunks, save_file=f'embeddings/query_{query_file}.emb')\n",
    "        \n",
    "        for snippet, query_embedding in zip(query_chunks, query_embeddings):\n",
    "            # Get the candidate chunk that is most similar to the snippet\n",
    "            candidate_chunk = get_most_similar_chunk(query_embedding, candidate_embeddings, candidate_chunks)\n",
    "            prediction = self.predict(query_chunk=snippet, candidate_chunk=candidate_chunk)\n",
    "            # print(prediction)\n",
    "            predictions.append(prediction.answer=='True')\n",
    "\n",
    "        return dspy.Prediction(predictions=predictions, resolved=self.resolve_function(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_chunking = PredictCitationAndResolve(max_windows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'query_file': 1054114, 'candidate_file': '14525920'}) (input_keys=None)\n",
      "Example({'cites': False}) (input_keys=None)\n",
      "Loading embeddings from candidate_14525920.emb\n",
      "Loading embeddings from query_1054114.emb\n",
      "Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# get an example\n",
    "example = trainset[0]\n",
    "example_x = example.inputs()\n",
    "example_y = example.labels()\n",
    "print(example_x)\n",
    "print(example_y)\n",
    "\n",
    "prediction = pipeline_chunking(**example_x)\n",
    "print(prediction)\n",
    "print(example_y.cites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: Pooled Motion Features for First-Person Videos M. S. Ryoo, Brandon Rothrock, and Larry Matthies Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA mryoo@jpl.nasa.gov Abstract In this paper, we present a new feature representation for ﬁrst-person videos. In ﬁrst-person video understanding (e.g., activity recognition), it is very important to capture both entire scene dynamics (i.e., egomotion) and salient lo- cal motion observed in videos. We describe a representa- tion framework based on time series pooling, which is de- signed to abstract short-term/long-term changes in feature descriptor elements. The idea is to keep track of how de- scriptor values are changing over time and summarize them to represent motion in the activity video. The framework is general, handling any types of per-frame feature descriptors including conventional motion descriptors like histogram of optical ﬂows (HOF) as well as appearance descriptors from more recent convolutional neural networks (CNN). We experimentally conﬁrm that our approach clearly outperforms previous feature representations including bag-of-visual-words and improved Fisher vector (IFV) when using identical underlying feature descriptors. We also conﬁrm that our feature representation has superior performance to existing state-of-the-art features like local spatio-temporal features and Improved Trajectory Features (originally developed for 3rd-person videos) when handling ﬁrst-person videos. Multiple ﬁrst-person activity datasets were tested under various settings to conﬁrm these ﬁndings. 1. Introduction First-person videos, also called egocentric videos, are videos taken from an actor’s own viewpoint. The vol- ume of egocentric video is rapidly increasing due to the recent ubiquity of small wearable devices. The main dif- ference between conventional 3rd-person videos and 1st- person videos is that, in 1st-person videos, the person wear- ing the camera is actively involved in the events being recorded. Strong egomotion is observed in ﬁrst-person videos, which makes them visually very unique (Figure 1). Automated understanding of such videos (i.e., ﬁrst-person activity recognition) is crucial for many societal applica- tions including quality-of-life systems to support daily liv-ing and video-based life-logging. Applications also include robot perception and human-robot interactions, since videos from the robot’s viewpoint naturally are in ﬁrst-person. Despite a massive amount of ﬁrst-person videos becom- ing available, approaches to semantically understand such videos have been very limited. This is particularly true for research on ‘motion features’ for ﬁrst-person videos, which serves as a fundamental component for visual grounding of actions and events. Even though there has been previous works on extraction of ﬁrst-person-speciﬁc semantic fea- tures like hand locations [11] and human gaze [13], fea- tures and representations designed to capture motion dy- namics of ﬁrst-person videos have been lacking. Repre- senting this egomotion\n",
      "Candidate Chunk: e a signal for potential event-detection. Trigger for Follow-up or ActionCrossing a predefined threshold leads to an in-depth analysis and further information gathering.A confirmed event or hint at an event leads to further information gathering, verification. that may not otherwise be detected in the routine collection of data from indicator-based surveillance. Events that may be detected in event-based surveillance include the following: rEvents, such as SARS, that are emerging or rarely occur and thus are not specifically part of the purview of standard indicator-based surveillance.rEvents that occur in real time but have not been detected by indicator-based surveillance, such as those events delayed by the required reporting procedures of notifying the designated health authority.rEvents that occur in populations that do not access health care through formal channels or in which formal, indicator-based sys- tems do not exist, such as events that occur in populations in rural areas or countries with a less established infrastructure for surveillance. Health information monitored via the Internet and social media is an important part of event-based surveillance and is most often the source on which many existing event-based surveillance systems fo- cus. Existing systems for such event-based monitoring contain use- ful retrieval features that give epidemiologists and public health sci- entists involved in surveillance quick access to information compiled from many media and news sources.9,10Other new health information Social Media and Internet-Based Data for Public Health Surveillance 13 technologies using new data sources from the Internet are important drivers of innovation in global surveillance, speeding up the collection and transmission of information to allow for better emergency prepared- ness or responses.11In research, event-based surveillance using data from the Internet, especially emails and online news sources, has been shown to identify surveillance trends comparable to those found us- ing established indicator-based surveillance methods.12-14In practice, however, such systems have not yet been widely accepted and inte- grated into the mainstream for use by national and international health authorities. We reviewed event-based surveillance systems that have actually been used, in order to examine the usefulness of event-based surveillance to existing surveillance efforts and its potential to improve future compre- hensive infectious disease surveillance systems. A Systematic Review of Event-Based Surveillance We conducted a systematic review to identify all currently established event-based surveillance systems used in infectious disease surveillance and to look at the type of data collected, the mode of data acquisition used by the system, and the overall purpose and function of each system. As members of a national scientific institute, our aim was to help health policy decision makers decide whether to incorporate new methods into comprehensive programs of surveillance that already con\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: is very essential for recognition of sports activities, accident activities for patient/health mon- itoring (e.g., a person collapsing), activities for surveil- lance/military (e.g., another person assaulting), and many others from ﬁrst-person videos. Most of the previous ﬁrst- person activity recognition works [9, 18] focused on the use of existing features and representations designed for con- ventional 3rd-person videos, without tailoring motion fea- tures for the ﬁrst-person case. This paper introduces a new feature representation named pooled time series (PoT). Our PoT is a general representation framework based on time series pooling of feature descriptors, which is particularly designed to cap- ture motion information in ﬁrst-person videos. Given a se- quence of per-frame feature descriptors (e.g., HOF or CNN features) from a video, PoT abstracts them by computing short-term/long-term changes in each descriptor element. The motivation is to develop a new feature representation that captures ‘details’ of entire scene dynamics displayed in ﬁrst-person videos, thereby obtaining better video recog- nition performances. Capturing egomotion information is crucial for recognition of ego-actions and interactions from ﬁrst-person videos, and our PoT representation allows the system to do so by keeping track of very detailed changes in feature descriptor values while suppressing noise. Mul- tiple novel pooling operators are introduced, and are com- bined with temporal ﬁlters to handle the temporal structure of human activities.arXiv:1412.6505v2  [cs.CV]  6 May 2015 (a) 1st-person videos   taken with wearable cameras  Camera   Human   Camera’s   field of view   (b) 3rd-person videos   Figure 1. Conceptual comparison between 1st-person videos and 3rd-person videos. Example snapshots from public ﬁrst-person datasets [9, 5] taken with human/animal wearable cameras and those from public 3rd-person dataset [17] are also illustrated. We experimentally conﬁrm that our proposed PoT repre- sentation clearly outperforms previous feature representa- tions such as bag-of-visual-words and improved Fisher vec- tor [14] on ﬁrst-person activity recognition. Both the global motion aspect and local motion aspect of ﬁrst-person videos are captured with our PoT by taking advantage of different types of descriptors, and we illustrate recognition accura- cies of our PoT with each of the descriptors as well as their combinations. Furthermore, we demonstrate that our com- bined PoT representation has superior performance to the best-known motion feature designed for 3rd-person videos [21], when handing 1st-person videos. 1.1. Related works Recognition from ﬁrst-person videos is a topic with an increasing amount of attention. There are works focusing on ﬁrst-person-speciﬁc features, including hand locations in ﬁrst-person videos [11] and human gaze estimation based on ﬁrst-person videos [13]. There also have been works on object recognition from ﬁrst-person videos [12, 15]. However, study on motion features for ﬁrst-person videos ha\n",
      "Candidate Chunk: e a signal for potential event-detection. Trigger for Follow-up or ActionCrossing a predefined threshold leads to an in-depth analysis and further information gathering.A confirmed event or hint at an event leads to further information gathering, verification. that may not otherwise be detected in the routine collection of data from indicator-based surveillance. Events that may be detected in event-based surveillance include the following: rEvents, such as SARS, that are emerging or rarely occur and thus are not specifically part of the purview of standard indicator-based surveillance.rEvents that occur in real time but have not been detected by indicator-based surveillance, such as those events delayed by the required reporting procedures of notifying the designated health authority.rEvents that occur in populations that do not access health care through formal channels or in which formal, indicator-based sys- tems do not exist, such as events that occur in populations in rural areas or countries with a less established infrastructure for surveillance. Health information monitored via the Internet and social media is an important part of event-based surveillance and is most often the source on which many existing event-based surveillance systems fo- cus. Existing systems for such event-based monitoring contain use- ful retrieval features that give epidemiologists and public health sci- entists involved in surveillance quick access to information compiled from many media and news sources.9,10Other new health information Social Media and Internet-Based Data for Public Health Surveillance 13 technologies using new data sources from the Internet are important drivers of innovation in global surveillance, speeding up the collection and transmission of information to allow for better emergency prepared- ness or responses.11In research, event-based surveillance using data from the Internet, especially emails and online news sources, has been shown to identify surveillance trends comparable to those found us- ing established indicator-based surveillance methods.12-14In practice, however, such systems have not yet been widely accepted and inte- grated into the mainstream for use by national and international health authorities. We reviewed event-based surveillance systems that have actually been used, in order to examine the usefulness of event-based surveillance to existing surveillance efforts and its potential to improve future compre- hensive infectious disease surveillance systems. A Systematic Review of Event-Based Surveillance We conducted a systematic review to identify all currently established event-based surveillance systems used in infectious disease surveillance and to look at the type of data collected, the mode of data acquisition used by the system, and the overall purpose and function of each system. As members of a national scientific institute, our aim was to help health policy decision makers decide whether to incorporate new methods into comprehensive programs of surveillance that already con\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: s been relatively limited, particularly those for ﬁrst-person activity recognition. Most of the works fo- cused on temporal segmentation of videos using optical ﬂow-based features, without taking advantage of high- dimensional image features for detailed recognition of high- level activities. Kitani et al. [9] worked on unsupervised learning of ego-actions and segmentation of videos based on it. A simple histogram based on optical ﬂow direc- tion/magnitude and frequency was constructed as a fea- ture representation, which can be viewed as an extension of HOF. Poleg et al. [16] introduced the use of displace- ment vectors similar to optical ﬂows for long-term tempo- ral segmentation, but they only focused on segmentation of relatively simple egomotion such as walking and wheeling. [18] investigated the ﬁrst-person activity recognition sce- narios by combining multiple features, while particularly focusing on recognition of interaction-level activities. Still,they used very conventional HOF and local spatio-temporal features [10, 3] together with general bag-of-visual-words representation, without any attempt to develop ﬁrst-person- speciﬁc features. 2. Pooled times series representation In this section, we introduce our new feature representa- tion named pooled time series (PoT), which is speciﬁcally designed for ﬁrst-person videos. The role of a feature ‘rep- resentation’ is to abstract a set of raw feature descriptors (e.g., histogram of oriented gradients) extracted from each video into a single vector representing the video. It con- verts a large number of high-dimensional descriptors into a single vector with a tractable dimensionality, allowing its result to serves as an input vector for classiﬁers (e.g., activity classiﬁcation). Existing feature representations in- clude bag-of-visual-words (BoW) and improved Fisher vec- tor (IFV), which converts a set of raw descriptors into a low- dimensional histogram. What we introduce in this section is a new feature representation that better abstracts motion displayed in ﬁrst-person videos. The overall pipeline of our PoT representation is as fol- lows. Given a ﬁrst-person video (i.e., a sequence of image frames), our approach ﬁrst extracts appearance/motion de- scriptors from each frame. As a result, a sequence of n- dimensional descriptor vectors is obtained where nis the size of the vector from each frame. Our approach interprets this as a set of ntime series. The idea is to keep track of how each element of the descriptor vector is changing over time (i.e., it becomes a function of time), and summarize such information to represent the activity video. Next, tem- poral pooling is performed: a set of temporal ﬁlters (i.e., time intervals) is applied to each time series and the system performs multiple types of pooling operations (e.g., max, sum, gradients, ...) per ﬁlter. Finally, the pooling results are concatenated to form the ﬁnal representation of the video. Figure 2 illustrates the overall process. Let each per-frame feature descriptor obtained at fram\n",
      "Candidate Chunk: e this information relies less on data structured and filtered through the aforementioned preestab- lished structures for surveillance. Event-based surveillance can identify events faster than indicator-based reporting procedures can, and it can detect events that occur in populations not able to access formal chan- nels for reporting. In addition, event-based surveillance can be used with other established indicator-based methods, thereby enhancing the combined arsenal for combatting critically prevalent pathogens with a high threat potential, such as influenza virus or Escherichia coli .T h es c i - entific literature recently referred to this comprehensive framework of combined activities from both indicator-based surveillance and event- based surveillance systems as “epidemic intelligence,” a contemporary understanding of the 1950s term with roots in public health innova- tion for surveillance systems at the US Centers for Disease Control and Prevention (CDC) and the establishment of the Epidemic Intelligence Service (EIS).4-8 Event-based surveillance continues to offer innovation for public health surveillance, for example, by capturing information about events Social Media and Internet-Based Data for Public Health Surveillance 11 TABLE 1 Indicator-Based and Event-Based Surveillance Systems Indicator-Based Event-Based Timeliness of Data InputInformation is input as soon as it is made available.Information is input as soon as it occurs. Timing is set immediate/ weekly/monthly. Possible delay between identification and notification.Timing varies, depending on when the data are available from those who have the information. Possible delay between identification and reporting. Reporting Clearly defined. Predefined or not Structure Reporting forms. Reporting dates. Teams analyze data at regular intervals. Moderated.predefined structure. Reporting forms flexible for qualitative and quantitative data. Teams analyze data at any time. Moderated or not moderated (eg, automatic). Timeliness of DetectionDepends on the time from the occurrence of the event (ie, the onset of the disease) until a diagnosis is available that fulfills a case definition. Depends on the time it takes for reporting through the stages of a hierarchical reporting structure.Depends on the time from the occurrence of the event (ie, onset of the disease) until the first mention occurs, which might be before diagnostic confirmation is available. Depends on the ability of the system and the time it takes to pick up a signal and to interpret it correctly. Thresholds for Signal GenerationStatistical methods are employed to identify increased numbers (clusters) in time or in space (or combinations of both) to generate aSignals are differentially generated (eg, human indexing in ProMED-mail) but rarely with automated statistical methods that Continued 12 E. Velasco et al. TABLE 1 —Continued Indicator-Based Event-Based signal for potential event-detection.identify increased numbers (clusters) in time or in space (or combinations of both) to generat\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: e t be denoted as Vt= [vt 1;vt 2;:::;vt n]. Our PoT representation framework interprets this sequence of vectors V1;:::;Vm (mis the number of video frames) as a set of time series, ff1(t);:::;f n(t)g. That is, each of our time series fi(t)cor- responding to the ith feature descriptor value is deﬁned as fi(t) =vt i. For each time series, temporal pooling is per- formed with a set of ktemporal ﬁlters, which essentially is a set of time intervals to make the system focus on each lo- cal time window:f[ts 1;te 1];:::;[ts k;te k]g. A temporal pyramid structure [2] is used in our implementation to obtain ﬁlters, but any number of ﬁlters with (overlapping) intervals can be used by our framework in principle. Finally, multiple pooling operators are applied for each ﬁlter and their results are concatenated to obtain the ﬁnal     11 31 21 1   nvvvv Per-frame   feature  descriptor  extraction       22 32 22 1   nvvvv      33 33 23 1   nvvvv      m nmmm vvvv  321CNN   Extracted  descriptor  vector  sequence  1st-person   activity  video   … … Time series representation  Per-frame feature representation   … Temporal pooling  Final representation   sum pooling   ‘histogram of time  series gradients’ pooling  … … …  …  …  n*m  dimensional data (e.g., n = 4096 features, m = 1000 frames)  n time series (e.g., 4096)  k temporal filters (e.g., 15)  n*k-D vector   (e.g., 61440)  … max pooling  Figure 2. Overall representation framework of our pooled time series (PoT). PoT feature representation of the video: x= [xop1 1[ts 1;te 1]; xop2 1[ts 1;te 1];\u0001\u0001\u0001; xopr n[ts k;te k]] (1) wherexopj ispeciﬁes that it is applying the jth pooling op- erator to the ith time series fi(t). Our PoT representation takes advantage of four different types of pooling operators including two newly introduced temporal pooling operators, which we discuss more in Subsection 2.2. Our framework of (i) extracting per-frame descriptors, (ii) interpreting them as a set of time series, and (iii) apply- ing various types of time series pooling and concatenating them provides the following three important abilities: First, (1) it preserves detailed dynamics displayed in each descriptor element as a time series, and allows the rep- resentation to capture both long-term motion and short-term information with multiple temporal ﬁlters. That is, depend- ing on the nature of the time series, our representation is able to capture subtle short-term motion by pooling from a ﬁlter with a small time interval as well as long-term motion by performing pooling with a large time interval. Such ﬂex- ibility is in contrast to previous bag-of-visual-words repre- sentation for global motion descriptors (e.g., the one used in [18]) that abstracts all descriptor values in one frame (or a subsequence of few frames) into a single discretized ‘vi- sual word’. In addition, (2) our representation explicitly im- poses temporal structure of the activity by decomposing the entire time interval to multiple subinterv\n",
      "Candidate Chunk: e this information relies less on data structured and filtered through the aforementioned preestab- lished structures for surveillance. Event-based surveillance can identify events faster than indicator-based reporting procedures can, and it can detect events that occur in populations not able to access formal chan- nels for reporting. In addition, event-based surveillance can be used with other established indicator-based methods, thereby enhancing the combined arsenal for combatting critically prevalent pathogens with a high threat potential, such as influenza virus or Escherichia coli .T h es c i - entific literature recently referred to this comprehensive framework of combined activities from both indicator-based surveillance and event- based surveillance systems as “epidemic intelligence,” a contemporary understanding of the 1950s term with roots in public health innova- tion for surveillance systems at the US Centers for Disease Control and Prevention (CDC) and the establishment of the Epidemic Intelligence Service (EIS).4-8 Event-based surveillance continues to offer innovation for public health surveillance, for example, by capturing information about events Social Media and Internet-Based Data for Public Health Surveillance 11 TABLE 1 Indicator-Based and Event-Based Surveillance Systems Indicator-Based Event-Based Timeliness of Data InputInformation is input as soon as it is made available.Information is input as soon as it occurs. Timing is set immediate/ weekly/monthly. Possible delay between identification and notification.Timing varies, depending on when the data are available from those who have the information. Possible delay between identification and reporting. Reporting Clearly defined. Predefined or not Structure Reporting forms. Reporting dates. Teams analyze data at regular intervals. Moderated.predefined structure. Reporting forms flexible for qualitative and quantitative data. Teams analyze data at any time. Moderated or not moderated (eg, automatic). Timeliness of DetectionDepends on the time from the occurrence of the event (ie, the onset of the disease) until a diagnosis is available that fulfills a case definition. Depends on the time it takes for reporting through the stages of a hierarchical reporting structure.Depends on the time from the occurrence of the event (ie, onset of the disease) until the first mention occurs, which might be before diagnostic confirmation is available. Depends on the ability of the system and the time it takes to pick up a signal and to interpret it correctly. Thresholds for Signal GenerationStatistical methods are employed to identify increased numbers (clusters) in time or in space (or combinations of both) to generate aSignals are differentially generated (eg, human indexing in ProMED-mail) but rarely with automated statistical methods that Continued 12 E. Velasco et al. TABLE 1 —Continued Indicator-Based Event-Based signal for potential event-detection.identify increased numbers (clusters) in time or in space (or combinations of both) to generat\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: als, which is very important for representing high-level activities. Finally, (3) it allows the system to take advantage of multiple types of pooling operators so that the representation captures differ- ent aspects of the data. As a result of our framework, each video is represented with one single vector having a tractable dimensionality.Activity recognition is performed by training/testing stan- dard classiﬁers (e.g., SVM classiﬁers) with these vectors. Our representation is able to cope with any type of genera- tive and discriminative classiﬁers in principle, and we show its superiority over others in Section 3.2. 2.1. Handling high-dimensional feature descriptors The proposed representation framework is very gen- eral in the aspect that it is able to cope with any types of per-frame image/motion descriptors such as histogram of oriented gradients (HOG) or histogram of optical ﬂows (HOF). Furthermore, it is particularly designed to han- dle high-dimensional per-frame image descriptors: image- based deep learning features which are also called convolu- tional neural network (CNN) features [7, 19]. These deep learning image features are obtained by snatching interme- diate outputs from internal convolutional layers of a CNN, pre-trained on image datasets. They can also be viewed as cascades of automatically learned image ﬁlters. These im- age descriptors are trained from large scale image datasets and have obtained highly successful results on image clas- siﬁcation/detection [4] as well as video classiﬁcation [8], performing superior to state-of-the-art hand-designed im- age descriptors such as HOG even without re-training the networks. Our motivation was to design a general representation that best takes advantage of such high-dimensional descrip- tors and conﬁrm that these CNN features are able to in- crease ﬁrst-person activity recognition performance signif- icantly together with other features. Each element of a CNN feature vector abstracts particular local/global appear- ance for a single frame, and (by extension) its time se- ries models how this local/global appearance is changing over time. As a human in the scene moves (e.g., changes his/her posture) and the camera changes its viewpoint be- cause of egomotion, certain CNN feature values will be- come activated/deactivated and our idea is to keep track of such changes to represent the activity video. In our experi- ments, we explicitly conﬁrm this while comparing our rep- resentation with the conventional representations. When us- ing CNN features as our base per-frame descriptors, we get a 4096-dimensional feature vector (i.e., n=4096) for each image frame by obtaining outputs of the last convolutional layer (e.g., stage 7 in [19]). 2.2. Temporal pooling operators Our PoT representation is constructed by applying multi- ple types of temporal pooling operators over each temporal ﬁlter (i.e., time interval). In this paper, we take advantage of four different types of pooling operators: conventional max pooling and sum pooling, and two types of o\n",
      "Candidate Chunk: e this information relies less on data structured and filtered through the aforementioned preestab- lished structures for surveillance. Event-based surveillance can identify events faster than indicator-based reporting procedures can, and it can detect events that occur in populations not able to access formal chan- nels for reporting. In addition, event-based surveillance can be used with other established indicator-based methods, thereby enhancing the combined arsenal for combatting critically prevalent pathogens with a high threat potential, such as influenza virus or Escherichia coli .T h es c i - entific literature recently referred to this comprehensive framework of combined activities from both indicator-based surveillance and event- based surveillance systems as “epidemic intelligence,” a contemporary understanding of the 1950s term with roots in public health innova- tion for surveillance systems at the US Centers for Disease Control and Prevention (CDC) and the establishment of the Epidemic Intelligence Service (EIS).4-8 Event-based surveillance continues to offer innovation for public health surveillance, for example, by capturing information about events Social Media and Internet-Based Data for Public Health Surveillance 11 TABLE 1 Indicator-Based and Event-Based Surveillance Systems Indicator-Based Event-Based Timeliness of Data InputInformation is input as soon as it is made available.Information is input as soon as it occurs. Timing is set immediate/ weekly/monthly. Possible delay between identification and notification.Timing varies, depending on when the data are available from those who have the information. Possible delay between identification and reporting. Reporting Clearly defined. Predefined or not Structure Reporting forms. Reporting dates. Teams analyze data at regular intervals. Moderated.predefined structure. Reporting forms flexible for qualitative and quantitative data. Teams analyze data at any time. Moderated or not moderated (eg, automatic). Timeliness of DetectionDepends on the time from the occurrence of the event (ie, the onset of the disease) until a diagnosis is available that fulfills a case definition. Depends on the time it takes for reporting through the stages of a hierarchical reporting structure.Depends on the time from the occurrence of the event (ie, onset of the disease) until the first mention occurs, which might be before diagnostic confirmation is available. Depends on the ability of the system and the time it takes to pick up a signal and to interpret it correctly. Thresholds for Signal GenerationStatistical methods are employed to identify increased numbers (clusters) in time or in space (or combinations of both) to generate aSignals are differentially generated (eg, human indexing in ProMED-mail) but rarely with automated statistical methods that Continued 12 E. Velasco et al. TABLE 1 —Continued Indicator-Based Event-Based signal for potential event-detection.identify increased numbers (clusters) in time or in space (or combinations of both) to generat\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate import Evaluate\n",
    "\n",
    "def metric(example, result):\n",
    "    '''Match metric'''\n",
    "    # print('inside metric')\n",
    "    # print(f'{example=}, {result=}')\n",
    "    return 1 if example.cites == result.resolved else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_13111019.emb\n",
      "Loading embeddings from candidate_14525920.emb\n",
      "Loading embeddings from query_12842965.emb\n",
      "Loading embeddings from candidate_26230598.emb\n",
      "Loading embeddings from candidate_17401731.emb\n",
      "Loading embeddings from query_1054114.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 12842965, 'candidate_file': '13111019', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 2  (50.0):   1%|          | 1/130 [00:03<07:09,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 1054114, 'candidate_file': '14525920', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_2197102.emb\n",
      "Loading embeddings from query_21724528.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):   2%|▏         | 3/130 [00:04<02:50,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_13935040.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 21724528, 'candidate_file': '17401731', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 2197102, 'candidate_file': '26230598', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_18428799.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 5  (80.0):   3%|▎         | 4/130 [00:06<02:49,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 18428799, 'candidate_file': '13935040', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_15723346.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 6  (66.7):   4%|▍         | 5/130 [00:08<02:21,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_14520569.emb\n",
      "Loading embeddings from candidate_11004850.emb\n",
      "Loading embeddings from candidate_209552.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 14520569, 'candidate_file': '15723346', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_1634096.emb\n",
      "Loading embeddings from query_12808563.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 7  (57.1):   5%|▌         | 7/130 [00:09<02:25,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 1634096, 'candidate_file': '209552', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 12808563, 'candidate_file': '11004850', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 8  (62.5):   6%|▌         | 8/130 [00:11<02:49,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_7913851.emb\n",
      "Loading embeddings from candidate_16950643.emb\n",
      "Loading embeddings from query_17630799.emb\n",
      "Loading embeddings from query_19225409.embLoading embeddings from candidate_518708.emb\n",
      "Loading embeddings from candidate_9456062.emb\n",
      "Loading embeddings from candidate_1063677.emb\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 10  (70.0):   7%|▋         | 9/130 [00:12<02:36,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 19225409, 'candidate_file': '16950643', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_1604520.emb\n",
      "Loading embeddings from query_15811205.emb\n",
      "Loading embeddings from query_888444.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 17630799, 'candidate_file': '7913851', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 1604520, 'candidate_file': '1063677', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 888444, 'candidate_file': '9456062', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 15811205, 'candidate_file': '518708', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 11  (72.7):   8%|▊         | 11/130 [00:14<02:09,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_28001085.emb\n",
      "Loading embeddings from candidate_6178111.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 13  (76.9):  10%|█         | 13/130 [00:15<01:54,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_49325027.emb\n",
      "Loading embeddings from query_21724528.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 49325027, 'candidate_file': '28001085', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 21724528, 'candidate_file': '6178111', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 15  (80.0):  12%|█▏        | 15/130 [00:17<01:36,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_1432085.emb\n",
      "Loading embeddings from candidate_12857779.emb\n",
      "Loading embeddings from candidate_3792942.emb\n",
      "Loading embeddings from candidate_20159414.emb\n",
      "Loading embeddings from candidate_5324521.emb\n",
      "Loading embeddings from query_14068125.emb\n",
      "Loading embeddings from query_14846121.emb\n",
      "Loading embeddings from query_13582167.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 14068125, 'candidate_file': '1432085', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_7487588.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 17  (82.4):  13%|█▎        | 17/130 [00:18<01:24,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_1604520.emb\n",
      "Loading embeddings from query_10124817.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 13582167, 'candidate_file': '3792942', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14846121, 'candidate_file': '12857779', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 1604520, 'candidate_file': '20159414', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_9951086.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 10124817, 'candidate_file': '5324521', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 9951086, 'candidate_file': '7487588', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 19  (84.2):  14%|█▍        | 18/130 [00:19<01:31,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_8806164.emb\n",
      "Loading embeddings from candidate_18074692.emb\n",
      "Loading embeddings from query_49541818.emb\n",
      "Loading embeddings from candidate_16236733.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 16 / 21  (76.2):  15%|█▌        | 20/130 [00:20<01:11,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_9022876.emb\n",
      "Loading embeddings from candidate_5041738.emb\n",
      "Loading embeddings from query_15811205.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 49541818, 'candidate_file': '8806164', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_1733200.emb\n",
      "Loading embeddings from query_929001.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 15811205, 'candidate_file': '18074692', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_10822829.emb\n",
      "Loading embeddings from candidate_11208402.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 929001, 'candidate_file': '9022876', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_15890292.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 10822829, 'candidate_file': '5041738', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 24  (79.2):  18%|█▊        | 23/130 [00:22<01:03,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 1733200, 'candidate_file': '16236733', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_14676755.emb\n",
      "Loading embeddings from query_51880918.emb\n",
      "Loading embeddings from candidate_7536915.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 14676755, 'candidate_file': '15890292', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 51880918, 'candidate_file': '11208402', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_49363931.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 25  (80.0):  18%|█▊        | 24/130 [00:23<01:05,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_21723747.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 49363931, 'candidate_file': '7536915', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 26  (76.9):  19%|█▉        | 25/130 [00:23<01:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_6530718.emb\n",
      "Loading embeddings from query_11718977.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21 / 27  (77.8):  21%|██        | 27/130 [00:25<01:14,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_17958964.emb\n",
      "Loading embeddings from candidate_14072234.emb\n",
      "Loading embeddings from candidate_17942323.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 11718977, 'candidate_file': '21723747', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 17958964, 'candidate_file': '6530718', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_18428799.emb\n",
      "Loading embeddings from candidate_891339.emb\n",
      "Loading embeddings from query_13266306.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 30  (80.0):  22%|██▏       | 29/130 [00:26<01:04,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 18428799, 'candidate_file': '14072234', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_4661204.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 4661204, 'candidate_file': '891339', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 13266306, 'candidate_file': '17942323', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_14292825.emb\n",
      "Loading embeddings from candidate_4533859.emb\n",
      "Loading embeddings from candidate_6592413.emb\n",
      "Loading embeddings from query_2261105.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24 / 30  (80.0):  23%|██▎       | 30/130 [00:27<01:11,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_29268022.embLoading embeddings from query_17958964.emb\n",
      "\n",
      "inside metric\n",
      "example=Example({'query_file': 2261105, 'candidate_file': '14292825', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 17958964, 'candidate_file': '6592413', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 26 / 32  (81.2):  25%|██▍       | 32/130 [00:29<01:18,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_9941351.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 29268022, 'candidate_file': '4533859', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_17958964.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 17958964, 'candidate_file': '9941351', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 27 / 33  (81.8):  25%|██▌       | 33/130 [00:30<01:30,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_18456846.emb\n",
      "Loading embeddings from query_22002351.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 28 / 35  (80.0):  26%|██▌       | 34/130 [00:31<01:30,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 22002351, 'candidate_file': '18456846', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 36  (80.6):  27%|██▋       | 35/130 [00:32<01:18,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_342649.emb\n",
      "Loading embeddings from candidate_10636659.emb\n",
      "Loading embeddings from candidate_53850543.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32 / 39  (82.1):  29%|██▉       | 38/130 [00:34<01:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_5749615.emb\n",
      "Loading embeddings from query_31742648.emb\n",
      "Loading embeddings from query_14638316.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 5749615, 'candidate_file': '342649', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14638316, 'candidate_file': '10636659', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 31742648, 'candidate_file': '53850543', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_1915951.emb\n",
      "Loading embeddings from candidate_16219282.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 42  (81.0):  32%|███▏      | 41/130 [00:36<01:04,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_3498240.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 3498240, 'candidate_file': '1915951', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_17630799.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 17630799, 'candidate_file': '16219282', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 35 / 43  (81.4):  32%|███▏      | 42/130 [00:37<01:08,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_215812180.emb\n",
      "Loading embeddings from candidate_3812096.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 44  (81.8):  34%|███▍      | 44/130 [00:38<01:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_5280973.emb\n",
      "Loading embeddings from query_1325297.emb\n",
      "Loading embeddings from query_2197102.emb\n",
      "Loading embeddings from query_11283266.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 1325297, 'candidate_file': '215812180', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 39 / 47  (83.0):  36%|███▌      | 47/130 [00:40<00:55,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 2197102, 'candidate_file': '3812096', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_7103019.emb\n",
      "Loading embeddings from candidate_8954831.emb\n",
      "Loading embeddings from candidate_207015066.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 11283266, 'candidate_file': '5280973', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_3501880.emb\n",
      "Loading embeddings from query_11718977.emb\n",
      "Loading embeddings from query_14846121.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 3501880, 'candidate_file': '7103019', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_296275.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 42 / 52  (80.8):  39%|███▉      | 51/130 [00:42<00:44,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 11718977, 'candidate_file': '8954831', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14846121, 'candidate_file': '207015066', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_9673612.emb\n",
      "Loading embeddings from candidate_15538672.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 9673612, 'candidate_file': '296275', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_53475.emb\n",
      "Loading embeddings from candidate_12559157.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 53475, 'candidate_file': '15538672', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_49363931.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 53  (81.1):  40%|████      | 52/130 [00:44<00:44,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 49363931, 'candidate_file': '12559157', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_13663736.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 43 / 53  (81.1):  41%|████      | 53/130 [00:44<01:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_2261077.emb\n",
      "Loading embeddings from query_27985376.emb\n",
      "Loading embeddings from query_53475.emb\n",
      "Loading embeddings from candidate_6664074.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 44 / 54  (81.5):  41%|████      | 53/130 [00:46<01:05,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 53475, 'candidate_file': '2261077', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 27985376, 'candidate_file': '13663736', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_12808563.emb\n",
      "Loading embeddings from candidate_5182310.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 45 / 55  (81.8):  42%|████▏     | 54/130 [00:46<01:27,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_111335.embLoading embeddings from candidate_7318157.emb\n",
      "\n",
      "inside metric\n",
      "example=Example({'query_file': 12808563, 'candidate_file': '6664074', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 46 / 56  (82.1):  43%|████▎     | 56/130 [00:48<01:14,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_9719320.embLoading embeddings from query_888444.emb\n",
      "\n",
      "inside metric\n",
      "example=Example({'query_file': 111335, 'candidate_file': '5182310', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 888444, 'candidate_file': '7318157', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_11283266.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 57  (82.5):  44%|████▍     | 57/130 [00:49<01:18,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metricLoading embeddings from candidate_14191393.emb\n",
      "\n",
      "example=Example({'query_file': 11283266, 'candidate_file': '9719320', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Error for example in dev set: \t\t negative seek value -1\n",
      "Loading embeddings from query_14068125.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 49 / 59  (83.1):  45%|████▌     | 59/130 [00:50<01:03,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 14068125, 'candidate_file': '14191393', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_45100885.emb\n",
      "Loading embeddings from candidate_1901454.emb\n",
      "Loading embeddings from candidate_11579427.emb\n",
      "Loading embeddings from query_13680434.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50.0 / 61  (82.0):  46%|████▌     | 60/130 [00:51<01:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_1733200.emb\n",
      "Loading embeddings from query_14024903.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 13680434, 'candidate_file': '45100885', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 1733200, 'candidate_file': '1901454', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14024903, 'candidate_file': '11579427', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.0 / 62  (82.3):  48%|████▊     | 62/130 [00:53<00:53,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_9794173.emb\n",
      "Loading embeddings from candidate_5388558.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.0 / 63  (81.0):  48%|████▊     | 63/130 [00:53<00:52,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_13266306.emb\n",
      "Loading embeddings from query_46921483.emb\n",
      "Loading embeddings from candidate_14285133.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 13266306, 'candidate_file': '9794173', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.0 / 65  (80.0):  49%|████▉     | 64/130 [00:54<00:45,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 46921483, 'candidate_file': '5388558', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_27985376.emb\n",
      "Loading embeddings from candidate_10440730.emb\n",
      "Loading embeddings from candidate_16655955.emb\n",
      "Loading embeddings from candidate_655973.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 27985376, 'candidate_file': '14285133', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_52012534.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.0 / 66  (80.3):  51%|█████     | 66/130 [00:55<00:38,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_9951086.emb\n",
      "Loading embeddings from candidate_3488076.emb\n",
      "Loading embeddings from query_22002351.emb\n",
      "Loading embeddings from query_14470504.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 9951086, 'candidate_file': '16655955', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 22002351, 'candidate_file': '655973', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 55.0 / 68  (80.9):  52%|█████▏    | 68/130 [00:56<00:38,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 52012534, 'candidate_file': '10440730', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14470504, 'candidate_file': '3488076', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.0 / 71  (81.7):  55%|█████▍    | 71/130 [00:59<00:44,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_1778892.emb\n",
      "Loading embeddings from query_11718977.emb\n",
      "Loading embeddings from candidate_5357461.emb\n",
      "Loading embeddings from candidate_15718014.emb\n",
      "Loading embeddings from candidate_1402069.embLoading embeddings from query_8402000.emb\n",
      "\n",
      "inside metric\n",
      "example=Example({'query_file': 11718977, 'candidate_file': '1778892', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.0 / 73  (80.8):  55%|█████▌    | 72/130 [01:01<00:52,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_13266306.emb\n",
      "Loading embeddings from query_46921483.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 8402000, 'candidate_file': '5357461', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_15184255.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 46921483, 'candidate_file': '1402069', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 13266306, 'candidate_file': '15718014', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.0 / 74  (81.1):  57%|█████▋    | 74/130 [01:02<00:50,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_17751516.emb\n",
      "Loading embeddings from candidate_49558658.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 17751516, 'candidate_file': '15184255', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_3041910.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.0 / 76  (81.6):  58%|█████▊    | 75/130 [01:03<00:51,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_15613461.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 3041910, 'candidate_file': '49558658', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_11984437.emb\n",
      "Loading embeddings from candidate_10460485.emb\n",
      "Loading embeddings from candidate_33036025.emb\n",
      "Loading embeddings from candidate_3128453.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63.0 / 77  (81.8):  59%|█████▉    | 77/130 [01:04<00:35,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metricLoading embeddings from candidate_14121435.emb\n",
      "\n",
      "example=Example({'query_file': 11984437, 'candidate_file': '15613461', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_5299262.emb\n",
      "Loading embeddings from query_11152703.emb\n",
      "Loading embeddings from query_5971084.emb\n",
      "Loading embeddings from candidate_5553697.emb\n",
      "Loading embeddings from query_49541818.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64.0 / 78  (82.1):  59%|█████▉    | 77/130 [01:04<00:35,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 11152703, 'candidate_file': '33036025', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 5299262, 'candidate_file': '10460485', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_13808159.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 5971084, 'candidate_file': '3128453', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 49541818, 'candidate_file': '14121435', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65.0 / 79  (82.3):  61%|██████    | 79/130 [01:05<00:39,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_11166004.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 13808159, 'candidate_file': '5553697', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66.0 / 81  (81.5):  62%|██████▏   | 81/130 [01:07<00:43,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_800241.emb\n",
      "Loading embeddings from candidate_52008963.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 800241, 'candidate_file': '11166004', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_4566846.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 68.0 / 84  (81.0):  64%|██████▍   | 83/130 [01:09<00:35,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 4566846, 'candidate_file': '52008963', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_2274347.emb\n",
      "Loading embeddings from query_888444.emb\n",
      "Loading embeddings from candidate_10268887.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70.0 / 86  (81.4):  66%|██████▌   | 86/130 [01:11<00:31,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_6927139.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 888444, 'candidate_file': '2274347', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_128024.emb\n",
      "Loading embeddings from query_29268022.emb\n",
      "Loading embeddings from query_62176925.emb\n",
      "Loading embeddings from query_4714486.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.0 / 88  (81.8):  67%|██████▋   | 87/130 [01:12<00:36,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 62176925, 'candidate_file': '6927139', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Error during API call: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "inside metric\n",
      "example=Example({'query_file': 29268022, 'candidate_file': '10268887', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_9343097.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 4714486, 'candidate_file': '128024', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Error for example in dev set: \t\t shapes (0,) and (1536,) not aligned: 0 (dim 0) != 1536 (dim 0)\n",
      "Loading embeddings from candidate_17307323.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72.0 / 90  (80.0):  69%|██████▉   | 90/130 [01:15<00:37,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_19631671.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 19631671, 'candidate_file': '17307323', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 73.0 / 91  (80.2):  70%|███████   | 91/130 [01:16<00:41,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_49668609.emb\n",
      "Loading embeddings from candidate_14898829.emb\n",
      "Loading embeddings from query_10124817.emb\n",
      "Loading embeddings from query_1323414.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74.0 / 92  (80.4):  71%|███████   | 92/130 [01:19<01:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_1011111.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 10124817, 'candidate_file': '49668609', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 1323414, 'candidate_file': '14898829', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_53310159.emb\n",
      "Loading embeddings from query_32722198.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77.0 / 95  (81.1):  72%|███████▏  | 94/130 [01:21<00:41,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_14068874.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 32722198, 'candidate_file': '1011111', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_1604520.emb\n",
      "Loading embeddings from query_51895111.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 1604520, 'candidate_file': '53310159', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77.0 / 96  (80.2):  73%|███████▎  | 95/130 [01:23<00:37,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 51895111, 'candidate_file': '14068874', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_206611975.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 77.0 / 96  (80.2):  74%|███████▍  | 96/130 [01:23<00:42,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during API call: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Loading embeddings from query_29268022.emb\n",
      "Loading embeddings from query_52148328.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.0 / 98  (79.6):  75%|███████▍  | 97/130 [01:26<00:53,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t shapes (0,) and (1536,) not aligned: 0 (dim 0) != 1536 (dim 0)\n",
      "inside metric\n",
      "example=Example({'query_file': 52148328, 'candidate_file': '206611975', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78.0 / 98  (79.6):  75%|███████▌  | 98/130 [01:27<00:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_6726135.emb\n",
      "Loading embeddings from query_17978942.emb\n",
      "Loading embeddings from candidate_4332898.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79.0 / 99  (79.8):  75%|███████▌  | 98/130 [01:29<00:48,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 17978942, 'candidate_file': '6726135', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_9470579.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 80.0 / 100  (80.0):  76%|███████▌  | 99/130 [01:30<00:59,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_52843977.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 9470579, 'candidate_file': '4332898', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_23580923.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.0 / 101  (80.2):  77%|███████▋  | 100/130 [01:32<00:50,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 23580923, 'candidate_file': '52843977', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 81.0 / 101  (80.2):  78%|███████▊  | 101/130 [01:32<00:46,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_16311309.emb\n",
      "Loading embeddings from candidate_206929190.emb\n",
      "Loading embeddings from query_11984437.emb\n",
      "Loading embeddings from query_1634096.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83.0 / 103  (80.6):  78%|███████▊  | 102/130 [01:34<00:49,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 11984437, 'candidate_file': '16311309', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_4718290.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 1634096, 'candidate_file': '206929190', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_8402000.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.0 / 104  (80.8):  79%|███████▉  | 103/130 [01:36<00:39,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 8402000, 'candidate_file': '4718290', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.0 / 104  (80.8):  80%|████████  | 104/130 [01:37<00:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_1225103.emb\n",
      "Loading embeddings from query_3081080.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 85.0 / 105  (81.0):  81%|████████  | 105/130 [01:42<01:03,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 3081080, 'candidate_file': '1225103', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_8835382.emb\n",
      "Loading embeddings from query_888444.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.0 / 106  (81.1):  81%|████████  | 105/130 [01:44<01:03,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 888444, 'candidate_file': '8835382', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_25531666.emb\n",
      "Loading embeddings from candidate_28347739.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 86.0 / 106  (81.1):  82%|████████▏ | 106/130 [01:45<01:08,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_14638316.emb\n",
      "Loading embeddings from query_21724528.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 87.0 / 107  (81.3):  82%|████████▏ | 106/130 [01:46<01:08,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 14638316, 'candidate_file': '25531666', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_393948.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88.0 / 108  (81.5):  82%|████████▏ | 107/130 [01:48<00:56,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 21724528, 'candidate_file': '28347739', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_1181640.emb\n",
      "Loading embeddings from query_586137.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88.0 / 109  (80.7):  84%|████████▍ | 109/130 [01:49<00:38,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metricLoading embeddings from query_1520250.emb\n",
      "\n",
      "example=Example({'query_file': 586137, 'candidate_file': '393948', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_12425538.emb\n",
      "Loading embeddings from candidate_6259144.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 1520250, 'candidate_file': '1181640', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_10148124.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 88.0 / 110  (80.0):  85%|████████▍ | 110/130 [01:50<00:29,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_5591866.embLoading embeddings from query_800241.emb\n",
      "\n",
      "Loading embeddings from candidate_1657636.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 89.0 / 111  (80.2):  85%|████████▌ | 111/130 [01:51<00:27,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metricLoading embeddings from candidate_14864236.emb\n",
      "\n",
      "example=Example({'query_file': 800241, 'candidate_file': '6259144', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_5971084.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 10148124, 'candidate_file': '12425538', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_12018209.emb\n",
      "Loading embeddings from query_14470504.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 91.0 / 113  (80.5):  87%|████████▋ | 113/130 [01:53<00:19,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 5971084, 'candidate_file': '5591866', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 12018209, 'candidate_file': '1657636', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14470504, 'candidate_file': '14864236', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_8861952.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93.0 / 115  (80.9):  88%|████████▊ | 114/130 [01:54<00:15,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_6601979.emb\n",
      "Loading embeddings from query_1634096.emb\n",
      "Loading embeddings from candidate_3654334.emb\n",
      "Loading embeddings from query_17958964.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94.0 / 116  (81.0):  88%|████████▊ | 115/130 [01:55<00:12,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_929001.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 1634096, 'candidate_file': '8861952', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 17958964, 'candidate_file': '6601979', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94.0 / 117  (80.3):  89%|████████▉ | 116/130 [01:56<00:12,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_15475.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 929001, 'candidate_file': '3654334', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_5304179.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 95.0 / 119  (79.8):  91%|█████████ | 118/130 [01:57<00:11,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_27985376.emb\n",
      "Loading embeddings from query_51895111.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 27985376, 'candidate_file': '15475', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 51895111, 'candidate_file': '5304179', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_8767528.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96.0 / 120  (80.0):  92%|█████████▏| 119/130 [01:58<00:09,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_19592640.emb\n",
      "Loading embeddings from candidate_25364178.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 96.0 / 120  (80.0):  92%|█████████▏| 120/130 [01:59<00:08,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_1634096.emb\n",
      "Loading embeddings from query_49907522.emb\n",
      "Loading embeddings from query_24927879.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 97.0 / 121  (80.2):  92%|█████████▏| 120/130 [01:59<00:08,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 1634096, 'candidate_file': '19592640', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 99.0 / 123  (80.5):  95%|█████████▍| 123/130 [02:01<00:05,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 49907522, 'candidate_file': '8767528', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 24927879, 'candidate_file': '25364178', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from candidate_8728653.emb\n",
      "Loading embeddings from candidate_1087898.emb\n",
      "Loading embeddings from candidate_38794958.emb\n",
      "Loading embeddings from query_32722198.embLoading embeddings from query_1520250.emb\n",
      "\n",
      "Loading embeddings from candidate_18470977.emb\n",
      "Loading embeddings from query_14676755.emb\n",
      "Loading embeddings from candidate_16545839.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 100.0 / 124  (80.6):  95%|█████████▌| 124/130 [02:03<00:06,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from query_14470504.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 32722198, 'candidate_file': '1087898', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 14676755, 'candidate_file': '38794958', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 1520250, 'candidate_file': '8728653', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Loading embeddings from query_19631671.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 103.0 / 127  (81.1):  98%|█████████▊| 127/130 [02:03<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 14470504, 'candidate_file': '18470977', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "inside metric\n",
      "example=Example({'query_file': 19631671, 'candidate_file': '16545839', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 104.0 / 128  (81.2):  98%|█████████▊| 128/130 [02:04<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_8412218.emb\n",
      "Loading embeddings from query_10148124.emb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105.0 / 129  (81.4):  99%|█████████▉| 129/130 [02:13<00:03,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside metric\n",
      "example=Example({'query_file': 10148124, 'candidate_file': '8412218', 'cites': False}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 105.0 / 130  (80.8): 100%|██████████| 130/130 [02:13<00:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from candidate_2127100.emb\n",
      "Loading embeddings from query_53079158.emb\n",
      "inside metric\n",
      "example=Example({'query_file': 53079158, 'candidate_file': '2127100', 'cites': True}) (input_keys={'candidate_file', 'query_file'}), result=Prediction(\n",
      "    predictions=[False, False, False, False, False, False, False, False, False, False],\n",
      "    resolved=False\n",
      ")\n",
      "Average Metric: 105.0 / 130  (80.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.77"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = Evaluate(devset=trainset, metric=metric, num_threads=8, display_progress=True, display_table=0, max_errors=100)\n",
    "evaluate(pipeline_chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: erwithmoreneighborsinthefor- eignlanguage. Followingthemethodin Zhuetal.(2017),there will be no edge between Chinese entity 福斯特 (Foust)and English entity Pistons, which implies awrongfactthat 福斯特 (Foust)doesnotbelong toPistons. Ourmethodenrichesthemissingrela- tion between entities 福斯特 (Foust)and活塞队 (Pistons)in incomplete Chinese KB through cor- responding English common neighbors, Allstar, NBA,etc.,asillustratedinFigure 1. 4.2 Comparable Sentences Generation To supervise the cross-lingual representation learningofwords,weautomaticallygeneratecom- parable sentences as cross-lingual training data. Comparable sentences are not translated paired sentences,butsentenceswiththesametopicindif- ferent languages. As shown in the middle layer (Figure1), the pair of sentences are comparable sentences: (1) “ Lawrence Michael Foust was an American basketball player who spent 12 seasons in NBA”, (2) “拉里·福斯特 (Lawrence Foust) 是 (was)美国 (American) NBA 联盟 (association) 的 (of)前(former)职业 (professional) 篮球 (basket- ball)运动员 (player)”. Inspired by the distant supervision technique in relation extraction, we assume that sentence sen kin Wikipedia articles of entity een iexplicitly or implicitly describes een i(Yamada et al. ,2017), and thatsen kshall express a relation between een i andeen jif another entity een jis insen k. Mean- while, we ﬁnd a comparable sentence szh k′in an- other language which satisﬁes szh k′containingezh j′ 231inWikipediaarticlesofChineseentity ezh i′,where ⟨een i;ezh i′⟩;⟨een j;ezh j′⟩ 2 Ren\u0000zh. AsshowninFig- ure1,thesentencesinthesecondlevelarecompa- rable due to the similar theme of the relation be- tween entity FoustandNBA. To ﬁnd this type of sentences, we search the anchors in the English aritcle and Chinese article of cross-lingual entity Foust, respectively, and extract the sentences in- cluding another crosslingual entity NBA. Compa- rable sentences can be regarded as cross-lingual contexts. Unfortunately, comparable sentences suffer fromtwoissuescausedbydistantsupervision: Wrong labelling . Take English as sample, there may be several sentences sen k;ljL l=1containing the sameentityeen jinthearticleof een i. Astraightfor- wardsolutionistoconcatenatethemintoalonger sentencesen k, but this increases the chance to in- cludeunrelatedsentences. Unbalanced information . Sometimes the pair ofsentencesconveyunbalancedinformation,e.g., theEnglishsentenceinthemiddlelayer(Figure 1) contains Foust spent 12 seasons in NBA whilethe comparableChinesesentencenot. Toaddresstheissues,weproposeknowledgeat- tentionandcross-lingualattentiontoﬁlteroutun- related information at sentence level, and at word levelrespectively. 5 Joint Representation Learning AsshowninFigure 2,therearethreecomponents inlearningcross-lingualwordandentityrepresen- tations, which are trained jointly. In this section, wewilldescribethemindetail. 5.1 Mono-lingual Representation Learning Following Yamadaetal. (2016);Caoetal.(2017), we learn mono-lingual word/entity embeddings based on corpus Dy, anchors Ayand entity net- work Gy. Capturingthe\n",
      "Candidate Chunk: on- sumption record whatsoever; this is known as a cold-start situa- tion [21]. These issues make traditional recommender-syst em ap- proachesdifﬁculttoapply,asshownbypriorempiricalstud ies[12]. It thus becomes indispensable to learn the goodness of match be- tweenuserinterestsandcontentwhenone orbothofthemaren ew. However, acquiring such information can be expensive and ma y reduce user satisfaction in the short term, raising the ques tion of optimallybalancingthetwocompetinggoals: maximizingus ersat- isfactioninthelongrun,andgatheringinformationaboutg oodness of match betweenuser interests and content. The above problem is indeed known as a feature-based explo- ration/exploitationproblem. Inthispaper,weformulatei tasacon- textual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users bas ed on con- textual information of the user and articles, while simulta neously adapting its article-selection strategy based on user-cli ck feedback to maximize total user clicks in the long run. We deﬁne a bandi t problem and then review some existing approaches in Section 2. Then, we propose a new algorithm, LinUCB, in Section 3 which has a similarregret analysis tothe best known algorithms fo r com- peting with the best linear predictor, with a lower computat ional overhead. We also address the problem of ofﬂineevaluation in Section 4, showing this is possible for anyexplore/exploit strat- egy when interactions are independent and identically dist ributed (i.i.d.),asmightbeareasonableassumptionfordifferent users. We then test our new algorithm and several existing algorithms using this ofﬂine evaluation strategyinSection5. 2. FORMULATION& RELATED WORK In this section, we deﬁne the K-armed contextual bandit prob- lem formally, and as an example, show how it can model the per- sonalized news article recommendation problem. We then dis cuss existing methods and their limitations. 2.1 A Multi-armed Bandit Formulation The problem of personalized news article recommendation ca n benaturallymodeledasamulti-armedbanditproblemwithco ntext information. Following previous work [18], we call it a contextual bandit.1Formally,acontextual-banditalgorithm Aproceedsindis- crete trialst= 1,2,3,...Intrialt: 1. The algorithm observes the current user utand a setAtof arms or actions together with their feature vectors xt,afor a∈At. Thevector xt,asummarizesinformationof boththe userutand arma, andwillbe referredtoas the context. 2. Based on observed payoffs in previous trials, Achooses an armat∈At, and receives payoff rt,atwhose expectation depends onboth the user utandthe armat. 3. The algorithm then improves its arm-selection strategy w ith the new observation, (xt,at,at,rt,at). Itis important toem- 1In the literature, contextual bandits are sometimes called bandits with covariate, bandits with side information, associativ e bandits, and associative reinforcement learning.phasize here that nofeedback (namely, the payoff rt,a) is observed for unchosen armsa/negationslash=at. The c\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: cooccurrenceinformation amongwordsandentities,theseembeddingsserve as the foundation and will be further extended to bilingualsettingsusingtheproposedcross-lingual regularizers,whichwillbedetailedinthenextsec- tion. Monolingually, we utilize a variant of Skip- grammodel( Mikolovetal. ,2013c)topredictthe contextsgivencurrentword/entity: Lm=∑ y2fen;zh g∑ xy i2fDy;Ay;GyglogP(C(xy i)jxy i)wherexy iis either a word or an entity, and C(xy i) denotes: (i)contextualwordsinapre-deﬁnedwin- dow ofxy iifxy i2 Dy, (ii) neighbor entities that linked toxy iifxy i2 Gy, (iii) contextual words of wy jifxy iisentityey iinananchor ⟨wy j;ey i⟩ 2 Ay. 5.2 Cross-lingual Entity Regularizer The bilingual EN Gen\u0000zhmerges entities in dif- ferent languages into a uniﬁed network, resulting in the possibility of using the same objective as in mono-lingual ENs. Thus, we naturally extend mono-lingualfunctiontocross-lingualsettings: Le=∑ ey i2fGen\u0000zhglogP(C′(ey i)jey i) where C′(ey i)denotes cross-lingual contexts— neighborentitiesindifferentlanguagesthatlinked toey i. Thus,byjointlylearningmono-lingualrep- resentation with cross-lingual entity regularizer, words and entities share more common contexts, and will have similar embeddings. As shown in Figure1,Englishentity NBAco-occurswithwords basketball andplayerintexts,sotheyareembed- ded closely in the semantic space. Meanwhile, cross-lingual linked entities NBAand NBA (zh) havesimilarrepresentationsduetothemostcom- monneighborentities,e.g., Foust. 5.3 Cross-lingual Sentence Regularizer Comparable sentences provide cross-lingual co- occurrence of words, thus, we can use them to learn similar embeddings for the words that fre- quentlyco-occurbyminimizingtheEuclideandis- tanceasfollows: Ls=∑ ⟨sen k;szh k′⟩2Sen\u0000zhjjsen k\u0000szh k′jj2 where sen k;szh k′aresentenceembeddings. TakeEn- glishassamplelanguage,wedeﬁneitastheaver- age sum of word vectors weighted by the combi- nationoftwotypesofattentions: sen k=L∑ l=1 (een m;sen k;l)∑ wen i2sen k;l ′(wen i;wzh j)wen i wheresen k;ljL l=1are sentences containing the same entity (as mentioned in Section 4.2), and  (een m;sen k;l)is knowledge attention that aims 232 Cross-lingualSentence RegularizerCross-lingual Entity Regularizer eNBAeAllstar\u0019500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599ACL 2018 Submission ***. Conﬁdential Review Copy. DO NOT DISTRIBUTE.QRW UHODWHG WR SDJH HQWLWLHV\u0011 7KXV\u000f ZH DVVLJQVPDOOHUZHLJKWWRVXFKVHQWHQFHVYLDVRIW\u0010DWWHQWLRQFRPSXWHG E\\ PHDVXULQJ VLPLODULW\\\u001dψ(ei,sk,l)∝sim(ei,/summationdisplaywm∈sk,lwm)\u000b\u0018\fZKHUHψ(ei,sk,l)LV NQRZOHGJH DWWHQWLRQ RI WKHlWKVXE\u0010VHQWHQFH IRUsk\u000fD Q GeiLV WKH FRUUHVSRQGLQJSDJH HQWLW\\\u0011 1RWH WKDWψ(ei,sk,l)=1LI WKHUH LVRQO\\ RQH VXE\u0010VHQWHQFH|sk|=1\u0011Cross-lingual Attention&URVV\u0010OLQJXDO DWWHQWLRQ IRFXVHV RQ SRWHQWLDO LQ\u0010IRUPDWLRQIURPFRPSDUDEOHVHQWHQFHVWKHPVHOYHV\u00117KLV LV\n",
      "Candidate Chunk: o estimate from data the conﬁdence interval of the parameters with which we can compute a UCB of the estimated arm payoff. Such an approach, however, isexpensive ingeneral. In this work, we show that a conﬁdence interval can be com- putedefﬁciently in closed form when the payoff model is linear, andcallthisalgorithm LinUCB.Forconvenience ofexposition,we ﬁrst describe the simpler form for disjointlinear models, and then consider thegeneral case of hybridmodels inSection3.2. Wenote LinUCBisageneric contextual bandit algorithms whichapplies to applications other than personalized news article recomme ndation. 3.1 LinUCB withDisjointLinear Models UsingthenotationofSection2.1,weassumetheexpectedpay off of an armais linear in its d-dimensional feature xt,awith some unknown coefﬁcient vector θθθ∗ a;namely, for all t, E[rt,a|xt,a] =x⊤ t,aθθθ∗ a. (2) This model is called disjointsince the parameters are not shared 2Note˜O(·)isthe same as O(·)but suppresses logarithmic factors.among different arms. Let Dabe a design matrix of dimension m×dat trialt, whose rows correspond to mtraininginputs ( e.g., mcontexts that are observed previously for article a), andba∈ Rmbe the corresponding response vector ( e.g., the corresponding mclick/no-click user feedback). Applying ridge regression to the trainingdata (Da,ca)gives anestimate of the coefﬁcients: ˆθθθa= (D⊤ aDa+Id)−1D⊤ aca, (3) whereIdis thed×didentitymatrix. Whencomponents in caare independent conditioned on corresponding rows in Da, it can be shown [27]that, withprobability atleast 1−δ, /vextendsingle/vextendsingle/vextendsinglex⊤ t,aˆθθθa−E[rt,a|xt,a]/vextendsingle/vextendsingle/vextendsingle≤α/radicalBig x⊤ t,a(D⊤aDa+Id)−1xt,a(4) for anyδ >0andxt,a∈Rd, whereα= 1 +/radicalbig ln(2/δ)/2is a constant. In other words, the inequality above gives a reaso nably tight UCB for the expected payoff of arm a, from which a UCB- type arm-selection strategycanbe derived: ateach trial t,choose atdef= argmax a∈At/parenleftbigg x⊤ t,aˆθθθa+α/radicalBig x⊤ t,aA−1 axt,a/parenrightbigg , (5) whereAadef=D⊤ aDa+Id. Theconﬁdence intervalinEq.(4)maybemotivated andderive d from other principles. For instance, ridge regression can a lso be interpreted as a Bayesian point estimate, where the posteri or dis- tribution of the coefﬁcient vector, denoted as p(θθθa), is Gaussian with mean ˆθθθaand covariance A−1 a. Given the current model, the predictive variance of the expected payoff x⊤ t,aθθθ∗ ais evaluated as x⊤ t,aA−1 axt,a, and then/radicalBig x⊤ t,aA−1 axt,abecomes the standard de- viation. Furthermore, in information theory [19], the diff erential entropy ofp(θθθa)is deﬁned as−1 2ln((2π)ddetAa). The entropy ofp(θθθa)when updated by the inclusion of the new point xt,athen becomes−1 2ln((2π)ddet(Aa+xt,ax⊤ t,a)). The entropy reduc- tion in the model posterior is1 2ln(1+x⊤ t,aA−1 axt,a). This quan- tity is often used to evaluate model improvement contribute d from xt,a. Therefore, the criterion for arm selection in Eq. (5) can al so be regarded as an additive trade-off between the payoff esti m\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: \u000f WR VRPH H[WHQW\u000f VLPLODU ZLWK VHOI\u0010DWWHQWLRQPHFKDQLVP\u000fZKLFKREWDLQVOHDUQLQJJXLGDQFHIURPVHQWHQFH LWVHOI\u000f EXW LQ FURVV\u0010OLQJXDO VHWWLQJV\u0011 7KHLQWXLWLRQLVWRÀQGSRVVLEOHZRUGDOLJQPHQWVDFURVVODQJXDJHV E\\ SLFNLQJ XS WKH PD[LPXP VLPLODULW\\\u001dψ′(wem,wzn)∝PD[wem∈sek,wzn∈szksim(wem,wzn)\u000b\u0019\f7KXV\u000f RQO\\ WKH FRPPRQ LQIRUPDWLRQ EHWZHHQFRPSDUDEOH VHQWHQFHV DUH PDLQWDLQHG\u0011 )RU H[DP\u0010SOH\u000b)LJXUH\u0014\f\u000fZRUGVAmerican\u000fbasketball\u000fplayerDUH VHOHFWHG GXH WR WKHLU FRUUHVSRQGLQJ WUDQVODWHG&KLQHVHZRUGV美国\u000f篮球\u000f运动员\u000fZKLOH12sea-sonsLQsekRU前(former)LQszkDUH GLVFDUGHG\u0011)LQDOO\\\u000f WKH VHQWHQFH HPEHGGLQJ LV WKH DYHUDJHVXPRIZRUGYHFWRUVZHLJKWHGE\\WKHFRPELQDWLRQRI WZR W\\SHV RI DWWHQWLRQV\u001dsek=/summationdisplaysek,l∈sekψ(eei,sek,l)/summationdisplaywem∈sek,lψ′(wem,wzn)wem\u000b\u001a\f5.4 Training2XU SURSRVHG PHWKRG NHHSV D FRQVLVWHQW DVVXPS\u0010WLRQ WKDW ZRUG\u0012HQWLW\\ VKDULQJ PRUH FRQWH[WV KDVVLPLODU UHSUHVHQWDWLRQV\u0011 7KXV\u000f ZH GHÀQH WKH RYHU\u0010DOO REMHFWLYH IXQFWLRQ DV WKH OLQHDU FRPELQDWLRQ\u001dL=Lm+Le+γLs\u000b\u001b\fZKHUHγLV D K\\SHU\u0010SDUDPHWHU WR WXQH WKH HIIHFWRI FURVV\u0010OLQJXDO VHQWHQFH UHJXODUL]HU\u000f DQG VHW WR\u0014L QH [ S H U L P H Q W V \u0011 : HX V HQ H J D W L Y HV D P S O L Q JD VLQ \u000b0LNRORY HW DO\u0011\u000f\u0015\u0013\u0014\u0016D\fI R UH I À F L H Q F \\ \u000fD Q GR S \u0010WLPL]H LW WKURXJK $GD*UDG 6*'\u00116E x p e r i m e n t s7RYHULI\\GLIIHUHQWDVSHFWVRIRXUPHWKRGV\u000fZHXVHVHSDUDWH WDVNV\u000f ZRUG WUDQVODWLRQ DQG HQWLW\\ UHODW\u0010HGQHVV\u000fDJDLQHVWFURVV\u0010OLQJXDOVHQWHQFHUHJXODUL]HUDQG FURVV\u0010OLQJXDO HQWLW\\ UHJXODUL]HU\u0011 7DNLQJ FURVV\u0010OLQJXDO HQWLW\\ OLQNLQJ DV D FDVH VWXG\\\u000f ZH WHVWLI\\MRLQW LQIHUHQFH DELOLW\\ EHWZHHQ ZRUGV DQG HQWLWLHVDFURVV ODQJXDJHV EDVHG RQ RXU HPEHGGLQJV\u00116.1 Experiment Settings:H FKRRVH :LNLSHGLD\u000f WKH $SULO \u0015\u0013\u0014\u001a GXPS\u000f DVWKH PXOWL\u0010OLQJXDO NQRZOHGJH EDVH DQG VL[ SRSXODUODQJXDJHV IRU HYDOXDWLRQ\u0011 :H SUHSURFHVV WKHP E\\ORZHUFDVH\u000fÀOWHULQJRXWV\\PEROVDQGORZIUHTXHQF\\ZRUGV DQG HQWLWLHV \u000bOHVV WKDQ \u0018\f\u000f DQG WRNHQL]LQJ&KLQHVHFRUSXVXVLQJ-LHED\u0019SDFNDJHDQG-DSDQHVHFRUSXVZLWKPHFDE\u001a\u00117 K HV W D W L V W L F VL VV K R Z QL Q7 D \u0010EOH\u0014\u001b\u00117DEOH \u0014\u001d0XOWL\u0010OLQJXDO.% 6WDWLVWLFV\u0011:RUG(QWLW\\YRFDEWRNHQYRFDEWRNHQ(Q\u0015P\u0014\u0011\u001cE\u0017P\u0013\u0011\u0017E=K\u0013\u0011\u0018\u0018P\u0013\u0011\u0014\u001aE\u0013\u0011\u0018\u001bP\u0013\u0011\u0013\u0019E(V\u0013\u0011\u001aP\u0013\u0011\u0017\u001bE\u0013\u0011\u001aP\u0013\u0011\u0013\u0017E-D\u0013\u0011\u0017\u0019P\u0013\u0011\u0017\u0018E\u0013\u0011\u001b\u001bP\u0013\u0011\u0013\u001bE,W\u0013\u0011\u0019\u001aP\u0013\u0011\u0017E\u0014P\u0013\u0011\u0014E7U\u0013\u0011\u0016\u0016P\u0013\u0011\u0013\u0018E\u0013\u0011\u0015P\u0013\u0011\u0013\u0014E)RU FURVV\u0010OLQJXDO VHWWLQJV\u000f ZH FKRRVH ÀYH ODQ\u0010JXDJHSDLUVWRFRPSDUHZLWKVWDWH\u0010RI\u0010WKH\u0010DUWPHWK\u0010RGV\u000f ZKRVH VWDWLVWLFV LV VKRZQ LQ 7DEOH\u0015\u0011) R O O R Z \u0010LQJ PRVW ZRUN\u000f ZH DGRSW (QJOLVK DV WKH SLYRW ODQ\u0010JXDJH GXH WR LWV GRPLQDQW UROH\u000f EXW DOVR WHVW =K\u0010-DIRU RWKHU FDVHV\u00117DEOH \u0015\u001d&URVV\u0010OLQJXDO 'DWD 6WDWLVWLFV\u0011&URVV\u0010OLQJ&RPSDUDEOH%L\u0010(1XDO /LQNV6HQWHQFHVER(Q\u0010(V\u0013\u0011\u001b\u0015P\u0017\u0011\u0019P\u0017\u0011\u001aP\u0013\u0011\u0017E(Q\u0010=K\u0013\u0011\u0018P\u0015P\u0017\u0011\u0019P\u0013\u0011\u0017E=K\u0010-D\u0013\u0011\u0015P\u0015P\u0014\u0011\u0017\u0019P\u0013\u0011\u0014\u0017E(Q\u0010,W\u0013\u0011\u001a\u0017P\u0016\u0011\u001bP\u0018P\u0013\u0011\u0017E(Q\u00107U\u0013\u0011\u0014\u0018P\u0013\u0011\u001a\u0018P\u0017\u0011\u0015P\u0013\u0011\u0017E:HVHWWUDLQLQJ HSRFK DV \u0015\u000f ZKLFK FRVWVQHDUO\\\u0015\u0013KRXUV RQ WKH VHUYHU ZLWK \u0019\u0017 FRUH &38 DQG \u0014\u001b\u001b*%PHPRU\\\u0011 7KH HPEHGGLQJ GLPHQVLRQ LV VHW DV \u0015\u0013\u0013DQG FRQWH[W ZLQGRZ VL]H DV \u0018\u0011 )RU HDFK SRVLWLYHH[DPSOH\u000f ZH VDPSOH \u0018 QHJDWLYH H[DPSOHV\u001c\u0011\u0019KWWSV\u001d\u0012\u0012JLWKXE\u0011FRP\u0012I[VM\\\u0012MLHED\u001aKWWS\u001d\u0012\u0012WDNX\u001c\u0014\u0013\u0011JLWKXE\u0011LR\u0012PHFDE\u0012\u001b)RUEUHYLW\\\u000fZHDGRSWWZR\u0010OHWWHUDEEUHYLDWLRQ(Q\u000f=K\u000f(V\u000f-D\u000f ,W DQG 7U IRU (QJOLVK\u000f &KLQHVH\u000f 6SDQLVK\u000f -DSDQHVH\u000f ,WDOLDQDQG 7XUNLVK\u000f UHVSHFWLYHO\\\u000f P IRU PLOOLRQ DQG E IRU ELOOLRQ\u0011\u001c)RU WKH SXUSRVH RI DQRQ\\PLW\\\u000f WKH FRGH DQG HPEHGGLQJV 5400401402\n",
      "Candidate Chunk: ayoff Rtup- dated. Otherwise, if the policy πselects a different arm from the one that was taken by the logging policy, then the event is ent irely ignored, and the algorithm proceeds to the next event withou t any other change initsstate. Note that, because the logging policy chooses each arm uni- formly at random, each event is retained by this algorithm wi th probability exactly 1/K, independent of everything else. This meansthattheeventswhichareretainedhavethesamedistri bution as if they were selected by D. As a result, we can prove that two processes areequivalent: theﬁrstisevaluatingthepolicy againstT real-world events from D, and the second is evaluating the policy using the policyevaluator on astream of logged events. THEOREM 1.Foralldistributions Dofcontexts,allpolicies π, allT,andall sequences ofevents hT, Pr Policy_Evaluator (π,S)(hT) = Pr π,D(hT) whereSis a stream of events drawn i.i.d. from a uniform random logging policyand D. Furthermore, theexpectednumber ofevents obtainedfromthestreamtogatherahistory hToflengthTisKT. This theorem says that everyhistoryhThas the identical prob- ability in the real world as in the policy evaluator. Many sta tistics of these histories, such as the average payoff RT/Treturned by Algorithm 3, are therefore unbiased estimates of the value o f the algorithmπ. Further,thetheoremstatesthat KTloggedevents are required, inexpectation, toretaina sample of size T. PROOF. Theproofisbyinductionon t= 1,...,Tstartingwith abasecaseoftheemptyhistorywhichhasprobability 1whent= 0Algorithm 3 Policy_Evaluator. 0: Inputs:T >0; policyπ;stream of events 1:h0←∅{Aninitiallyemptyhistory} 2:R0←0{Aninitiallyzero totalpayoff} 3:fort= 1,2,3,...,Tdo 4:repeat 5: Getnext event (x1,...,xK,a,ra) 6:untilπ(ht−1,(x1,...,xK)) =a 7:ht←CONCATENATE (ht−1,(x1,...,xK,a,ra)) 8:Rt←Rt−1+ra 9:endfor 10: Output: RT/T under both methods of evaluation. In the inductive case, ass ume that we have for all t−1: Pr Policy_Evaluator (π,S)(ht−1) = Pr π,D(ht−1) and want toprove the same statement for any history ht. Since the data is i.i.d. and any randomization in the policy is indepen dent of randomization in the world, we need only prove that conditio ned on the history ht−1the distribution over the t-th event is the same for eachprocess. Inother words, we must show: Pr Policy_Evaluator (π,S)((xt,1,...,xt,K,a,rt,a)|ht−1) =Pr D(xt,1,...,xt,K,rt,a) Pr π(ht−1)(a|xt,1,...,xt,K). Since the arm ais chosen uniformly at random in the logging pol- icy, the probability that the policy evaluator exits the inn er loop is identicalfor anypolicy, anyhistory,anyfeatures,andany arm,im- plying this happens for the last event with the probability o f the lastevent, PrD(xt,1,...,xt,K,rt,a). Similarly,sincethepolicy π’s distribution over arms is independent conditioned on the hi story ht−1and features (xt,1,...,xt,K), the probability of arm ais just Prπ(ht−1)(a|xt,1,...,xt,K). Finally,since each event from the stream isretained withpr oba- bilityexactly 1/K,theexpectednumberrequiredtoretain Tevents is exactlyKT. 5. EXPERIMENTS In t\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: 403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499ACL 2018 Submission ***. Conﬁdential Review Copy. DO NOT DISTRIBUTE.As t r a i g h t f o r w a r ds o l u t i o ni st oc o n c a t e n a t et h e minto a longer sentencesenk,b u tt h i si n c r e a s e st h echance to include unrelated sentences.Unbalanced information.S o m e t i m e st h ep a i ro fsentences convey different information, e.g., theEnglish sentence in layer 2 (Figure1)c o n t a i n sFoust spent 12 seasons in NBAwhile the compa-rable Chinese sentence not.To address the issues, we propose knowledge at-tention and cross-lingual attention to ﬁlter out un-related information at sentence level and at wordlevel, respectively.[[这里感觉改动较大]]5 Joint Representation Learning5.1 Mono-lingual Representation LearningFollowing(Yamada et al.,2016;Caoetal.,2017),we learn mono-lingual word/entity embeddingsbased on corpusDy,a n c h o r sAyand entity net-workGy.W e u t i l i z e a v a r i a n t o f S k i p - g r a mmodel (Mikolov et al.,2013c)t op r e d i c tt h ec o n -texts given current word/entity:Lm=/summationdisplayy∈{en,zh}/summationdisplayxyi∈{Dy,Ay,Gy}logP(C(xyi)|xyi)(1)wherexyiis either a word or an entity, andC(xyi)denotes: (i)contextualwordsinapre-deﬁnedwin-dow ofxyiifxyi∈Dy,( i i )n e i g h b o re n t i t i e st h a tlinked toxyiifxyi∈Gy,( i i i )c o n t e x t u a lw o r d so fwyjifxyiis entityeyiin an anchor⟨wyj,eyi⟩∈Ay.5.2 Cross-lingual Entity RegularizerThe bilingual ENGen−zhmerges entities in dif-ferent languages into a uniﬁed network, resultingin the possibility of using the same objective asin mono-lingual ENs. Thus, we naturally extendmono-lingual function to cross-lingual settings:Le=/summationdisplayeyi∈{Gen−zh}logP(C′(eyi)|eyi)(2)whereC′(eyi)denotes cross-lingual contexts—neighborentitiesindifferentlanguagesthatlinkedtoeyi.T h u s ,b yj o i n t l yl e a r n i n gm o n o - l i n g u a lr e p -resentation with cross-lingual entity regularizer,words and entities share more common contexts,and will have similar embeddings. As shown inFigure1,EnglishentityNBAco-occurswithwordsbasketballandplayerin texts, so they are embed-dedcloseinthesemanticspace. Meanwhile,cross-linguallinkedentitiesNBAandNBA(zh)havesim-ilarrepresentationsduetothemostcommonneigh-bor entities, e.g.,Foust.5.3 Cross-lingual Sentence RegularizerComparable sentences provide cross-lingual co-occurrence of words, thus, we learn similar em-beddingsforthewordsthatfrequentlyco-occurto-gether by minimizing the Euclidean distance:Ls=/summationdisplay⟨senk,szhk′⟩∈Sen−zh||senk−szhk′||2(3)wheresenk,szhk′aresentenceembeddings. TakeEn-glish as sample language, we deﬁne it as the aver-age sum of word vectors weighted by the combi-nation of two types of attentions:senk=/summationdisplayl∈Lψ(eenm,senk,l)/summationdisplayweni∈senk,lψ′(weni,wzhj)weni(4)where{s\n",
      "Candidate Chunk: ely. We now consider the more interesting case with hybridmodels. In many applications including ours, it is helpful to use fea tures thataresharedbyallarms,inadditiontothearm-speciﬁcon es. For example, in news article recommendation, a user may prefer o nly articlesaboutpoliticsforwhichthisprovidesamechanism . Hence, it is helpful to have features that have both shared and non-s hared components. Formally, we adopt the following hybrid model by adding another linear term tothe right-hand side of Eq. (2): E[rt,a|xt,a] =z⊤ t,aβββ∗+x⊤ t,aθθθ∗ a, (6) wherezt,a∈Rkis the feature of the current user/article combina- tion, andβββ∗is anunknown coefﬁcient vector common to all arms. This model is hybrid in the sense that some of the coefﬁcients βββ∗ are shared byall arms,while others θθθ∗ aare not. For hybrid models, we can no longer use Algorithm 1 as the conﬁdence intervalsofvarious armsarenot independent due tothe shared features. Fortunately, there is an efﬁcient way to co mpute an UCB along the same line of reasoning as in the previous sec- tion. The derivation relies heavily on block matrix inversi on tech- niques. Due to space limitation, we only give the pseudocode in Algorithm 2 (where lines 5 and 12 compute the ridge-regressi on solution of the coefﬁcients, and line 13 computes the conﬁde nce interval), and leave detailed derivations to a full paper. H ere, weAlgorithm 2 LinUCBwithhybrid linear models. 0: Inputs:α∈R+ 1:A0←Ik(k-dimensional identitymatrix) 2:b0←0k(k-dimensional zerovector) 3:fort= 1,2,3,...,Tdo 4: Observe features ofall arms a∈At:(zt,a,xt,a)∈Rk+d 5:ˆβββ←A−1 0b0 6:for alla∈Atdo 7:ifais newthen 8: Aa←Id(d-dimensional identitymatrix) 9: Ba←0d×k(d-by-kzero matrix) 10: ba←0d×1(d-dimensional zero vector) 11: endif 12: ˆθθθa←A−1 a/parenleftBig ba−Baˆβββ/parenrightBig 13:st,a←z⊤ t,aA−1 0zt,a−2z⊤ t,aA−1 0B⊤ aA−1 axt,a+ x⊤ t,aA−1 axt,a+x⊤ t,aA−1 aBaA−1 0B⊤ aA−1 axt,a 14:pt,a←z⊤ t,aˆβββ+x⊤ t,aˆθθθa+α√st,a 15:endfor 16: Choose arm at= argmax a∈Atpt,awith ties broken arbi- trarily,and observe a real-valued payoff rt 17:A0←A0+B⊤ atA−1 atBat 18:b0←b0+B⊤ atA−1 atbat 19:Aat←Aat+xt,atx⊤ t,at 20:Bat←Bat+xt,atz⊤ t,at 21:bat←bat+rtxt,at 22:A0←A0+zt,atz⊤ t,at−B⊤ atA−1 atBat 23:b0←b0+rtzt,at−B⊤ atA−1 atbat 24:endfor onlypoint outtheimportant factthatthealgorithmiscompu tation- ally efﬁcient since the building blocks in the algorithm ( A0,b0, Aa,Ba, andba) all have ﬁxed dimensions and can be updated incrementally. Furthermore, quantities associated with a rms not existing inAtno longer get involved in the computation. Finally, we can also compute and cache the inverses ( A−1 0andA−1 a) pe- riodically instead of at the end of each trial to reduce the pe r-trial computational complexity to O(d2+k2). 4. EVALUATION METHODOLOGY Compared to machine learning in the more standard supervise d setting,evaluationofmethodsinacontextual banditsetti ngisfrus- tratinglydifﬁcult. Ourgoalhereistomeasuretheperforma nceofa bandit algorithm π, that is,a rule for selecting anarm at each time stepbasedontheprecedinginteractions(suchast\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predict if the two chunks are related by a citation.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Query Chunk: Query chunk to compare to the candidate chunk.\n",
      "Candidate Chunk: Candidate chunk to compare to the query chunk.\n",
      "Answer: either True or False (Respond with a single bool value)\n",
      "\n",
      "---\n",
      "\n",
      "Query Chunk: enk,l|l∈L}is a set of sentences con-taining the same entity (as mentioned in Sec-tion4.2), andψ(eenm,senk,l)is knowledge attentionthat aims at ﬁlter out wrong labelling sentences,andψ′(weni,wzhj)iscross-lingualattentiontodealwith the unbalanced information through possiblealigned words.Knowledge AttentionSupposethatsentences{senk,l|l∈L}containthesameentitiesinarticlesofentityeym,thewrongla-belling errors increase because some of them arealmostirrelevanttoeym.K n o w l e d g ea t t e n t i o na i m sat ﬁltering out wrong labelled sentences throughsmaller weights and related sentences with higherweights. Thus,wedeﬁneitproportionaltothesim-ilarity betweensyk,landeym:ψ(eym,syk,l)∝sim(eym,/summationdisplaywyi∈syk,lwyi)(5)wheresimis similarity measurement, and weuse cosine similarity in the rest of the pa-per. We normalize knowledge attention such that/summationtextLlψ(eym,syk,l)=1.Cross-lingual AttentionInspiredbyself-attentionmechanism(Linetal.,2017b),wemotivatecross-lingualattentionfocus-ingonpotentialinformationfromcomparablesen-tencesthemselves. Theintuitionistoﬁndpossiblealignedwordsbetweenlanguages,andﬁlteroutthewords without alignments. We deﬁne it accordingto the maximum similarity:Mono-lingual Representation Learning Zh 1000001002003004005006007008009010011012013014015016017018019020021022023024025026027028029030031032033034035036037038039040041042043044045046047048049050051052053054055056057058059060061062063064065066067068069070071072073074075076077078079080081082083084085086087088089090091092093094095096097098099ACL 2018 Submission ***. Conﬁdential Review Copy. DO NOT DISTRIBUTE.Joint Representation Learning of Cross-lingual Words and Entities viaAttentive Distant SupervisionAnonymous ACL submissionAbstractJointly learning word and entity represen-tationsbeneﬁtsmanyNLPtasks,whilehasnotbeenwellexploredincross-lingualset-tings. In this paper, we propose a novelmethod that integrates cross-lingual wordandentityrepresentationlearningtoenablejointinferenceamongknowledgebaseandtext across languages, capturing mutuallycomplementary knowledge. Instead of re-liance on parallel data, we automaticallygeneratecross-lingualtrainingdataviadis-tantsupervisionovermulti-lingualknowl-edge bases. We also propose two typesof knowledge attention and cross-lingualattention to select the most informativewords and ﬁlter out noise, which will fur-ther improve the performance. In exper-iments, separate tasks of word translationand entity relatedness demonstrate the ef-fectivenessofourmethodwithanaveragegain of 20% and 3% over baselines, re-spectively. Using entity linking as a casestudy, the results on benchmark datasetverify the quality of our embeddings.1I n t r o d u c t i o nMulti-lingual knowledge bases (KB), storing mil-lions of entities and their facts in various lan-guages,providerichstructuredknowledgeforun-derstandingnaturallanguagebeyondtexts. Mean-while,abundanttextcorpuscontainslargeamountofpotentialknowledgecomplementarytoexistingKBs. Therefore, researchers leverage both typesof resources to improve various na\n",
      "Candidate Chunk: on- sumption record whatsoever; this is known as a cold-start situa- tion [21]. These issues make traditional recommender-syst em ap- proachesdifﬁculttoapply,asshownbypriorempiricalstud ies[12]. It thus becomes indispensable to learn the goodness of match be- tweenuserinterestsandcontentwhenone orbothofthemaren ew. However, acquiring such information can be expensive and ma y reduce user satisfaction in the short term, raising the ques tion of optimallybalancingthetwocompetinggoals: maximizingus ersat- isfactioninthelongrun,andgatheringinformationaboutg oodness of match betweenuser interests and content. The above problem is indeed known as a feature-based explo- ration/exploitationproblem. Inthispaper,weformulatei tasacon- textual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users bas ed on con- textual information of the user and articles, while simulta neously adapting its article-selection strategy based on user-cli ck feedback to maximize total user clicks in the long run. We deﬁne a bandi t problem and then review some existing approaches in Section 2. Then, we propose a new algorithm, LinUCB, in Section 3 which has a similarregret analysis tothe best known algorithms fo r com- peting with the best linear predictor, with a lower computat ional overhead. We also address the problem of ofﬂineevaluation in Section 4, showing this is possible for anyexplore/exploit strat- egy when interactions are independent and identically dist ributed (i.i.d.),asmightbeareasonableassumptionfordifferent users. We then test our new algorithm and several existing algorithms using this ofﬂine evaluation strategyinSection5. 2. FORMULATION& RELATED WORK In this section, we deﬁne the K-armed contextual bandit prob- lem formally, and as an example, show how it can model the per- sonalized news article recommendation problem. We then dis cuss existing methods and their limitations. 2.1 A Multi-armed Bandit Formulation The problem of personalized news article recommendation ca n benaturallymodeledasamulti-armedbanditproblemwithco ntext information. Following previous work [18], we call it a contextual bandit.1Formally,acontextual-banditalgorithm Aproceedsindis- crete trialst= 1,2,3,...Intrialt: 1. The algorithm observes the current user utand a setAtof arms or actions together with their feature vectors xt,afor a∈At. Thevector xt,asummarizesinformationof boththe userutand arma, andwillbe referredtoas the context. 2. Based on observed payoffs in previous trials, Achooses an armat∈At, and receives payoff rt,atwhose expectation depends onboth the user utandthe armat. 3. The algorithm then improves its arm-selection strategy w ith the new observation, (xt,at,at,rt,at). Itis important toem- 1In the literature, contextual bandits are sometimes called bandits with covariate, bandits with side information, associativ e bandits, and associative reinforcement learning.phasize here that nofeedback (namely, the payoff rt,a) is observed for unchosen armsa/negationslash=at. The c\n",
      "Answer:\u001b[32m False\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'237TomasMikolov,QuocVLe,andIlyaSutskever.2013b.\\nExploitingsimilaritiesamonglanguagesformachine\\ntranslation. CoRR.\\nTomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.\\nCorrado, and Jeffrey Dean. 2013c. Distributed rep-\\nresentations of words and phrases and their compo-\\nsitionality. In NIPS.\\nDavid Milne and Ian H. Witten. 2008. An effective,\\nlow-cost measure of semantic relatedness obtained\\nfromwikipedialinks. In AAAI.\\nMike Mintz, Steven Bills, Rion Snow, and Daniel Ju-\\nrafsky.2009. Distantsupervisionforrelationextrac-\\ntionwithoutlabeleddata. In ACL/IJCNLP .\\nAditya Mogadala and Achim Rettinger. 2016. Bilin-\\ngual word embeddings from parallel and non-\\nparallel corpora for cross-language text classiﬁca-\\ntion. In HLT-NAACL .\\nThien Huu Nguyen, Nicolas Fauceglia, Mariano Ro-\\ndriguez Muro, Oktie Hassanzadeh, Alﬁo Massimil-\\nianoGliozzo,andMohammadSadoghi.2016. Joint\\nlearning of local and global features for entity link-\\ningvianeuralnetworks. In COLING.\\nSebastian Ruder, Ivan Vulić, and Anders Søgaard.\\n2017. A survey of cross-lingual word embedding\\nmodels. arXiv preprint arXiv:1706.04902 .\\nTianzeShi,ZhiyuanLiu,YangLiu,andMaosongSun.\\n2015. Learning cross-lingual word embeddings via\\nmatrixco-factorization. In ACL.\\nRadu Soricut and Nan Ding. 2016. Multilingual word\\nembeddingsusingmultigraphs. CoRR.\\nMihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,\\nand Christopher D. Manning. 2012. Multi-instance\\nmulti-label learning for relation extraction. In\\nEMNLP-CoNLL .\\nKristina Toutanova, Danqi Chen, Patrick Pantel, Hoi-\\nfungPoon,PallaviChoudhury,andMichaelGamon.\\n2015. Representingtextforjointembeddingoftext\\nandknowledgebases. In EMNLP.\\nIvan Vulic and Marie-Francine Moens. 2015. Bilin-\\ngualwordembeddingsfromnon-paralleldocument-\\naligned data applied to bilingual lexicon induction.\\nInACL.\\nIvanVulicandMarie-FrancineMoens.2016. Bilingual\\ndistributed word representations from document-\\nalignedcomparabledata. JAIR.\\nZhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng\\nChen. 2014. Knowledge graph and text jointly em-\\nbedding. In EMNLP.\\nZhigang Wang and Juan-Zi Li. 2016. Text-enhanced\\nrepresentationlearningforknowledgegraph. In IJ-\\nCAI.Jason Weston, Antoine Bordes, Oksana Yakhnenko,\\nand Nicolas Usunier. 2013a. Connecting language\\nandknowledgebaseswithembeddingmodelsforre-\\nlationextraction. In ACL.\\nJason Weston, Antoine Bordes, Oksana Yakhnenko,\\nand Nicolas Usunier. 2013b. Connecting language\\nandknowledgebaseswithembeddingmodelsforre-\\nlationextraction. In EMNLP.\\nHaiyang Wu, Daxiang Dong, Xiaoguang Hu, Dian-\\nhai Yu, Wei He, Hua Wu, Haifeng Wang, and Ting\\nLiu. 2014. Improve statistical machine translation\\nwithcontext-sensitivebilingualsemanticembedding\\nmodel. In EMNLP.\\nJiawei Wu, Ruobing Xie, Zhiyuan Liu, and Maosong\\nSun. 2016. Knowledge representation via joint\\nlearning of sequential text and knowledge graphs.\\nCoRR.\\nMin Xiao and Yuhong Guo. 2014. Distributed word\\nrepresentationlearningforcross-lingualdependency\\nparsing. In CoNLL.\\nIkuya Yamada, Hiroyuki Shindo, Hideaki Takeda, and\\nYoshiyasuTakefuji.2016. Jointlearningoftheem-\\nbedding of words and entities for named entity dis-\\nambiguation. In CoNLL.\\nIkuya Yamada, Hiroyuki Shindo, Hideaki Takeda, and\\nYoshiyasuTakefuji.2017. Learningdistributedrep-\\nresentations of texts and entities from knowledge\\nbase. TACL.\\nBishan Yang and Tom M. Mitchell. 2017. Leverag-\\ningknowledgebasesinlstmsforimprovingmachine\\nreading. In ACL.\\nDaojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao.\\n2015. Distant supervision for relation extraction\\nvia piecewise convolutional neural networks. In\\nEMNLP.\\nJingZhang,YixinCao,LeiHou,JuanziLi,andHai-Tao\\nZheng.2017a. Xlink: anunsupervisedbilingualen-\\ntity linking system. In Chinese Computational Lin-\\nguistics and Natural Language Processing Based on\\nNaturally Annotated Big Data .\\nMeng Zhang, Yang Liu, Huanbo Luan, and Maosong\\nSun. 2017b. Adversarial training for unsupervised\\nbilinguallexiconinduction. In ACL.\\nYuan Zhang, David Gaddy, Regina Barzilay, and\\nTommi S. Jaakkola. 2016. Ten pairs to tag - multi-\\nlingualpostaggingviacoarsemappingbetweenem-\\nbeddings. In HLT-NAACL .\\nHao Zhu, Ruobing Xie, Zhiyuan Liu, and Maosong\\nSun. 2017. Iterative entity alignment via joint\\nknowledgeembeddings. In IJCAI.\\nWill Y. Zou, Richard Socher, Daniel M. Cer, and\\nChristopherD.Manning.2013. Bilingualwordem-\\nbeddings for phrase-based machine translation. In\\nEMNLP.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PdfReader('darwin/query_papers/53079158.pdf').pages[-1].extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
